torch runtimes backing the Docling pipeline. We will deliver updates on this topic at in a future
version of this report.
Table 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our
test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution
(TTS), computed throughput in pages per second, and the peak memory used (resident set size) for
both the Docling-native PDF backend and for the pypdfium backend, using 4 and 16 threads.
CPU
Thread
budget
native backend
pypdfium backend
TTS
Pages/s
Mem
TTS
Pages/s
Mem
Apple M3 Max
(16 cores)
4
177 s
1.27
6.20 GB
103 s
2.18
2.56 GB
16
167 s
1.34
92 s
2.45
Intel(R) Xeon
E5-2690
(16 cores)
4
375 s
0.60
6.16 GB
239 s
0.94
2.42 GB
16
244 s
0.92
143 s
1.57
5
Applications
Thanks to the high-quality, richly structured document conversion achieved by Docling, its out-
put qualifies for numerous downstream applications. For example, Docling can provide a base
for detailed enterprise document search, passage retrieval or classification use-cases, or support
knowledge extraction pipelines, allowing specific treatment of different structures in the document,
such as tables, figures, section structure or references. For popular generative AI application pat-
terns, such as retrieval-augmented generation (RAG), we provide quackling, an open-source package
which capitalizes on Doclingâ€™s feature-rich document output to enable document-native optimized
vector embedding and chunking. It plugs in seamlessly with LLM frameworks such as LlamaIn-
dex [8]. Since Docling is fast, stable and cheap to run, it also makes for an excellent choice to build
document-derived datasets. With its powerful table structure recognition, it provides significant ben-
efit to automated knowledge-base construction [11, 10]. Docling is also integrated within the open
IBM data prep kit [6], which implements scalable data transforms to build large-scale multi-modal
training datasets.
6
Future work and contributions
Docling is designed to allow easy extension of the model library and pipelines. In the future, we
plan to extend Docling with several more models, such as a figure-classifier model, an equation-
recognition model, a code-recognition model and more. This will help improve the quality of con-
version for specific types of content, as well as augment extracted document metadata with ad-
ditional information. Further investment into testing and optimizing GPU acceleration as well as
improving the Docling-native PDF backend are on our roadmap, too.
We encourage everyone to propose or implement additional features and models, and will
gladly take your inputs and contributions under review. The codebase of Docling is open for use
and contribution, under the MIT license agreement and in alignment with our contributing guidelines
included in the Docling repository. If you use Docling in your projects, please consider citing this
technical report.
References
[1] J. AI. Easyocr: Ready-to-use ocr with 80+ supported languages. https://github.com/
JaidedAI/EasyOCR, 2024. Version: 1.7.0.
[2] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard,
E. Burovski, G. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison,
W. Feng, J. Gong, M. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. La-
zos, M. Lezcano, Y. Liang, J. Liang, Y. Lu, C. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso,
M. Saroufim, M. Y. Siraichi, H. Suk, M. Suo, P. Tillet, E. Wang, X. Wang, W. Wen, S. Zhang,
X. Zhao, K. Zhou, R. Zou, A. Mathews, G. Chanan, P. Wu, and S. Chintala. Pytorch 2: Faster
5
